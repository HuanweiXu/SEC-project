{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from datetime import date\n",
    "from itertools import zip_longest\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Generator, List, Optional, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "from aiohttp import ClientSession\n",
    "import regex\n",
    "from tenacity import retry\n",
    "import os\n",
    "\n",
    "from constants import _FORMS, _LOCATIONS\n",
    "\n",
    "class secc_2023:\n",
    "    count = 0\n",
    "    total = None\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0\"}\n",
    "    path = os.getcwd()\n",
    "    _LOGGER = logging.getLogger(__name__)\n",
    "    _CC_REGEX = regex.compile(R\"[\\p{Cc}\\p{Cf}]+\", regex.V1)\n",
    "    _DISPLAY_NAME_REGEX = regex.compile(R\"(.*) \\(CIK (\\d{10})\\)\", regex.V1)\n",
    "    df = pd.DataFrame()\n",
    "    error_list = list()\n",
    "    \n",
    "    def __init__(self,_PHRASES,_FILING_TYPES,_DATE_START,_CIKS,_DATE_END,_CIKS_PER_QUERY = 5, update_constant=False):\n",
    "        self._PHRASES = _PHRASES\n",
    "        self._FILING_TYPES = _FILING_TYPES\n",
    "        self._DATE_START = _DATE_START\n",
    "        self._DATE_END = _DATE_END\n",
    "        #self._CIKS = self.CIK(_CIKS)\n",
    "        self._CIKS_PER_QUERY = _CIKS_PER_QUERY\n",
    "        self._CIKS = self.chop_ciks(_CIKS,_CIKS_PER_QUERY)#....\n",
    "        self.total = len(list(self._CIKS))\n",
    "        \n",
    "        if (not os.path.exists(f\"{self.path}constants.py\")) or self.update_constant:\n",
    "            self.__constant_update\n",
    "    \n",
    "    @staticmethod\n",
    "    def CIK(file):\n",
    "        with open(file, \"r\", encoding=\"UTF-8\") as f:\n",
    "            try:\n",
    "                _ciks = [f\"{int(cik):010}\" for cik in f.read().splitlines()]\n",
    "                return _ciks\n",
    "            except IOError as e:\n",
    "                    raise ValueError(f\"{file} is not a valid file\") from e\n",
    "                \n",
    "    def chop_ciks(\n",
    "    ciks: Optional[Union[Path, int, str, List[Any]]],\n",
    "    ciks_per_query: int\n",
    ") -> Generator[Optional[List[str]], None, None]:\n",
    "    # defaults to None\n",
    "        _ciks: Optional[List[str]] = None\n",
    "        # if the provided parameter is a Path, read the CIKs from the file\n",
    "        if isinstance(ciks, Path):\n",
    "            try:\n",
    "                with open(ciks, \"r\", encoding=\"UTF-8\") as f:\n",
    "                    try:\n",
    "                        _ciks = [f\"{int(cik):010}\" for cik in f.read().splitlines()]\n",
    "                    except ValueError as e:\n",
    "                        raise ValueError(f\"{ciks} contains invalid CIKs\") from e\n",
    "            except IOError as e:\n",
    "                raise ValueError(f\"{ciks} is not a valid file\") from e\n",
    "        # if it's an iterable of values, treat all values as CIKs\n",
    "        elif isinstance(ciks, list):\n",
    "            try:\n",
    "                _ciks = [f\"{int(cik):010}\" for cik in ciks]\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"{ciks} is not a valid CIK list\") from e\n",
    "        # if it's a single string, consider it as a single CIK\n",
    "        elif isinstance(ciks, str):\n",
    "            try:\n",
    "                _ciks = [f\"{int(ciks):010}\"]\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"{ciks} is not a valid CIK\") from e\n",
    "        # same as previous with the preferred (int) type\n",
    "        elif isinstance(ciks, int):\n",
    "            _ciks = [f\"{ciks:010}\"]\n",
    "\n",
    "        if _ciks:\n",
    "            for i in range(0, len(_ciks), ciks_per_query):\n",
    "                yield _ciks[i:i + ciks_per_query]\n",
    "        else:\n",
    "            yield None\n",
    "           \n",
    "                \n",
    "    async def excution(self):\n",
    "        semaphore = asyncio.Semaphore(10)\n",
    "        async with ClientSession(raise_for_status=True, headers=self.headers) as client :\n",
    "            for ciks_batch in self._CIKS:\n",
    "            # Create tasks for fetching data\n",
    "                    loop = asyncio.get_event_loop()\n",
    "                    tasks = [\n",
    "                        loop.create_task(self.fetch(semaphore \n",
    "                    = semaphore ,\n",
    "                    client = client,\n",
    "                    phrases=self._PHRASES,\n",
    "                    cik=cik,\n",
    "                    start=self._DATE_START,\n",
    "                    end=self._DATE_END,\n",
    "                    forms=form))\n",
    "                        for cik in ciks_batch\n",
    "                        for form in self._FILING_TYPES\n",
    "                    ]\n",
    "                    loop.run_until_complete(asyncio.wait(tasks))\n",
    "                    #results = await asyncio.gather(*tasks)\n",
    "                    # #results = await asyncio.gather(*tasks)\n",
    "                    # # loop = asyncio.get_event_loop()\n",
    "                    # # loop.run_until_complete(results)\n",
    "                    # result = await asyncio.wait(tasks)\n",
    "                    # asyncio.get_event_loop().run_until_complete(result)\n",
    "                    self.count += self._CIKS_PER_QUERY\n",
    "                    print(f\"Complete {self.count}/{self.total}\")\n",
    "            self.df = self.df.reset_index(drop=True)\n",
    "        #Wait for tasks to complete and unwrap the results\n",
    "    \n",
    "                    \n",
    "\n",
    "   \n",
    "        \n",
    "    @staticmethod \n",
    "    async def __constant_update():\n",
    "        async with ClientSession(raise_for_status=True) as c:\n",
    "            async with c.get(\"https://www.sec.gov/edgar/search/js/edgar_full_text_search.js\") as res:\n",
    "                _script = await res.text()\n",
    "\n",
    "            with open(\"constants.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"_FORMS = \")\n",
    "                json.dump({\n",
    "                    form.pop(\"form\"): form\n",
    "                    for form in eval(re.search(\n",
    "                        R\"^const forms = (\\[\\r?\\n(?: {4}\\{.*?\\},*\\r?\\n)*(?: {4}\\{.*?\\})\\r?\\n\\])\\.sort\",\n",
    "                        _script,\n",
    "                        regex.MULTILINE\n",
    "                    )[1])\n",
    "                }, f, indent=4)\n",
    "\n",
    "                f.write('\\n')\n",
    "\n",
    "                f.write(\"_LOCATIONS = \")\n",
    "                json.dump(dict(eval(re.search(\n",
    "                    R\"^const locationsArray = (\\[\\r?\\n(?: {4}\\[.*?\\],\\r?\\n)*(?: {4}\\[.*?\\])\\r?\\n\\]);\",\n",
    "                    _script,\n",
    "                    regex.MULTILINE\n",
    "                )[1])), f, indent=4)\n",
    "\n",
    "                f.write('\\n')\n",
    "    \n",
    "    @retry\n",
    "    async def fetch(self,semaphore,client,phrases,cik,end,forms,start='2001-01-01',range = 'custom',category= 'custom',entity=None):\n",
    "        \n",
    "        q = \" \".join(f\"\\\"{phrase}\\\"\" for phrase in phrases)\n",
    "        print(q)\n",
    "        forms = \" \".join(form for  form in forms) #iterator\n",
    "        print(forms)\n",
    "        data = {'q':q,\n",
    "                'startdt':start,\n",
    "                'enddt':end,\n",
    "                'ciks':cik,\n",
    "                'dataRange':'custom',\n",
    "                'category':'custom',\n",
    "                'forms':forms}\n",
    "        url = 'https://efts.sec.gov/LATEST/search-index'\n",
    "        \n",
    "        tem_df = pd.DataFrame()\n",
    "        async with semaphore,client.request(method='get',url=url,params = data) as res:\n",
    "            await asyncio.sleep(1)\n",
    "            if res.status == 200:\n",
    "                url = res.url\n",
    "                print(url)\n",
    "                json = await res.json()\n",
    "                #page_info = json['query'] --- Unconvered empty input ciks and needed of page swtich \n",
    "                total = int(json[\"hits\"][\"total\"][\"value\"])\n",
    "                hits = json[\"hits\"][\"hits\"]\n",
    "                # match_result = regex.search(r'\"from\":(\\d+),\"size\":(\\d+),\"aggregations\":', page_info) \n",
    "                # if match_result:\n",
    "                #     from_value = match_result.group(1)\n",
    "                #     size_value = match_result.group(2)\n",
    "                #if total > 30 : #show limited of per page\n",
    "                #self.error_list.append(data)\n",
    "                #raise ValueError(f\"CIK = {cik} fetch error. Status Code = {res.status}\")\n",
    "        for hit in hits:\n",
    "            tem_df = pd.concat([tem_df,self._parse_hit(hit)])\n",
    "        \n",
    "        try:\n",
    "            total == tem_df.shape[0]\n",
    "        except:\n",
    "            print(f\"Length of CIK:{cik} is not equal\")\n",
    "        finally:\n",
    "            return pd.concat([self.df,tem_df])\n",
    "                        \n",
    "\n",
    "\n",
    "    def _concat_to_url(self,cik: str, adsh: str, filename: str) -> str:\n",
    "        return f\"https://www.sec.gov/Archives/edgar/data/{cik}/{adsh}/{filename}\"\n",
    "\n",
    "\n",
    "\n",
    "    @retry\n",
    "    async def _download(self,semaphore: asyncio.Semaphore, url: str, client) -> Tuple[bytes, str]:\n",
    "        async with semaphore, client.get(url) as res:\n",
    "            await asyncio.sleep(1)\n",
    "            if res.ok:\n",
    "                content = await res.read()\n",
    "                return content\n",
    "            raise ValueError(f\"Status code : {res.status}\")\n",
    "\n",
    "\n",
    "    def _parse_display_name(self,s: str, cik: str):\n",
    "        if s is not None and (m := self._DISPLAY_NAME_REGEX.fullmatch(s)):\n",
    "            if (scik := m[2]) != cik:\n",
    "                self._LOGGER.warning(f\"mismatched CIK: {scik} (parsed from \\\"{s}\\\") v.s. {cik}\")\n",
    "            return m[1], scik\n",
    "        return s, cik\n",
    "\n",
    "    @staticmethod\n",
    "    def chop_ciks(\n",
    "        ciks: Optional[Union[Path, int, str, List[Any]]],\n",
    "        ciks_per_query: int\n",
    "    ) -> Generator[Optional[List[str]], None, None]:\n",
    "        # defaults to None\n",
    "        _ciks: Optional[List[str]] = None\n",
    "        # if the provided parameter is a Path, read the CIKs from the file\n",
    "        if isinstance(ciks, Path):\n",
    "            try:\n",
    "                with open(ciks, \"r\", encoding=\"UTF-8\") as f:\n",
    "                    try:\n",
    "                        _ciks = [f\"{int(cik):010}\" for cik in f.read().splitlines()]\n",
    "                    except ValueError as e:\n",
    "                        raise ValueError(f\"{ciks} contains invalid CIKs\") from e\n",
    "            except IOError as e:\n",
    "                raise ValueError(f\"{ciks} is not a valid file\") from e\n",
    "        # if it's an iterable of values, treat all values as CIKs\n",
    "        elif isinstance(ciks, list):\n",
    "            try:\n",
    "                _ciks = [f\"{int(cik):010}\" for cik in ciks]\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"{ciks} is not a valid CIK list\") from e\n",
    "        # if it's a single string, consider it as a single CIK\n",
    "        elif isinstance(ciks, str):\n",
    "            try:\n",
    "                _ciks = [f\"{int(ciks):010}\"]\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"{ciks} is not a valid CIK\") from e\n",
    "        # same as previous with the preferred (int) type\n",
    "        elif isinstance(ciks, int):\n",
    "            _ciks = [f\"{ciks:010}\"]\n",
    "\n",
    "        if _ciks:\n",
    "            for i in range(0, len(_ciks), ciks_per_query):\n",
    "                yield _ciks[i:i + ciks_per_query]\n",
    "        else:\n",
    "            yield None\n",
    "\n",
    "\n",
    "    def _parse_hit(self,hit: Dict[str, Any]): \n",
    "        _id = hit[\"_id\"]\n",
    "        source = hit[\"_source\"]\n",
    "\n",
    "        adsh, filename = _id.split(':')\n",
    "        filename_main, filename_ext = filename.rsplit('.', 1)\n",
    "        xsl = source[\"xsl\"]\n",
    "        if xsl and filename_ext.lower() == \"xml\":\n",
    "            filename_main = f\"{xsl}/{filename_main}\"\n",
    "        filename = f\"{filename_main}.{filename_ext}\"\n",
    "        file_nums = source[\"file_num\"]\n",
    "        film_nums = source[\"film_num\"]\n",
    "        rows = pd.DataFrame((\n",
    "            [_id, *self._parse_display_name(display_name, cik), loc.split(\",\")[0], _LOCATIONS.get(code), file_num, film_num]\n",
    "            for display_name, cik, loc, code, file_num, film_num in zip_longest(\n",
    "                source[\"display_names\"],\n",
    "                source[\"ciks\"],\n",
    "                source[\"biz_locations\"],\n",
    "                source[\"biz_states\"], \n",
    "                file_nums if isinstance(file_nums, list) else [file_nums] if file_nums else (),\n",
    "                film_nums if isinstance(film_nums, list) else [film_nums] if film_nums else ()\n",
    "            )\n",
    "        ), columns=[\"id\", \"entity_name\", \"cik\", \"located\", \"incorporated\", \"file_num\", \"film_num\"], copy=False)#, dtype=str\n",
    "        form = source[\"form\"]\n",
    "        root_form = source[\"root_form\"]\n",
    "        form_title = \"\"\n",
    "        if root_form in _FORMS:\n",
    "            form_title = f\" ({_FORMS[root_form]['title']})\"\n",
    "        file_type = source[\"file_type\"]\n",
    "        if not file_type:\n",
    "            file_type = source[\"file_description\"]\n",
    "        if not file_type:\n",
    "            file_type = filename\n",
    "        ciks = rows.loc[0,\"cik\"]\n",
    "        info = pd.DataFrame({\n",
    "            \"entity_name\":rows['entity_name'],\n",
    "            \"id\": _id,\n",
    "            \"form_file\": f\"{form}{form_title}{'' if form == file_type else f' {file_type}'}\",\n",
    "            \"file_date\": source[\"file_date\"],\n",
    "            \"period_ending\": source.get(\"period_ending\", None),\n",
    "            \"file_ext\": filename_ext,\n",
    "            \"url\": self._concat_to_url(ciks, adsh.replace('-', ''), filename),\n",
    "            \"parser\": None#getattr(parsers, f\"_parse_{filename_ext.lower()}\", None)\n",
    "        },copy=False,dtype=str)#, dtype=object\n",
    "        result = pd.merge(rows,info,how=\"left\",on=\"id\")\n",
    "        del result[\"id\"]\n",
    "        return result.reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_paragraphs(html, keywords):#Need to support more extension like pdf,txt and etc?\n",
    "        paragraph_pattern = regex.compile(r'<span.*?>(.*?)</span>', regex.DOTALL)\n",
    "        paragraphs = paragraph_pattern.findall(html)\n",
    "\n",
    "        result_paragraphs = [paragraph for paragraph in paragraphs if any(keyword in paragraph for keyword in keywords)]\n",
    "\n",
    "        return result_paragraphs\n",
    "\n",
    "    def CIK(file):\n",
    "        with open(file, \"r\", encoding=\"UTF-8\") as f:\n",
    "            try:\n",
    "                _ciks = [f\"{int(cik):010}\" for cik in f.read().splitlines()]\n",
    "                return _ciks\n",
    "            except IOError as e:\n",
    "                    raise ValueError(f\"{file} is not a valid file\") from e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gray/project/secc_2023_beta_1.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gray/project/secc_2023_beta_1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m                 \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mtasks)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gray/project/secc_2023_beta_1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gray/project/secc_2023_beta_1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     asyncio\u001b[39m.\u001b[39;49mrun(main())\n",
      "File \u001b[0;32m~/miniconda3/envs/summer/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m coroutines\u001b[39m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39ma coroutine was expected, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "from pathlib import Path\n",
    "\n",
    "async def main():\n",
    "    _PHRASES = [\"data breach\"]\n",
    "    _FILING_TYPES = [\"10-Q\"]\n",
    "    _DATE_START = \"2000-12-01\"\n",
    "    _DATE_END = \"2023-12-12\"\n",
    "    _CIKS = Path(\"sample_input_file.txt\")\n",
    "\n",
    "    scratch = secc_2023(_PHRASES, _FILING_TYPES, _DATE_START, _CIKS, _DATE_END)\n",
    "    semaphore = asyncio.Semaphore(10)\n",
    "\n",
    "    async with ClientSession(raise_for_status=True, headers=scratch.headers) as client:\n",
    "        for ciks in scratch._CIKS:\n",
    "            for form in scratch._FILING_TYPES:\n",
    "                tasks = [\n",
    "                    scratch.fetch(\n",
    "                        semaphore=semaphore,\n",
    "                        client=client,\n",
    "                        phrases=scratch._PHRASES,\n",
    "                        cik=cik,\n",
    "                        start=scratch._DATE_START,\n",
    "                        end=scratch._DATE_END,\n",
    "                        forms=form\n",
    "                    ) for cik in ciks\n",
    "                ]\n",
    "                await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PHRASES = [\"data breach\"]\n",
    "_FILING_TYPES = [\"10-Q\"]\n",
    "_DATE_START = \"2000-12-01\"\n",
    "_DATE_END = \"2023-12-12\"\n",
    "_CIKS = Path(\"sample_input_file.txt\")\n",
    "\n",
    "scratch = secc_2023(_PHRASES, _FILING_TYPES, _DATE_START, _CIKS, _DATE_END)\n",
    "semaphore = asyncio.Semaphore(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in scratch._CIKS:\n",
    "    i.next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
